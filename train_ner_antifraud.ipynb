{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化版中文诈骗场景 NER 微调训练脚本\n",
    "本Notebook用于加载`data/ner_training_data.csv`，并用BERT进行命名实体识别微调。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from collections import Counter\n",
    "\n",
    "# 设置日志\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f'使用设备: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. 加载数据\n",
    "try:\n",
    "    # 读取CSV文件，将空值替换为空字符串\n",
    "    df = pd.read_csv('data/ner_training_data.csv', encoding='utf-8')\n",
    "    \n",
    "    # 检查并处理缺失值\n",
    "    if df['labels'].isnull().any():\n",
    "        logger.warning(f'发现 {df[\"labels\"].isnull().sum()} 个缺失值，将被替换为空字符串')\n",
    "        df['labels'] = df['labels'].fillna('')\n",
    "    \n",
    "    # 数据预处理\n",
    "    df['labels'] = df['labels'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "    \n",
    "    # 移除空标签的行\n",
    "    df = df[df['labels'].apply(len) > 0]\n",
    "    \n",
    "    logger.info(f'成功加载数据，共 {len(df)} 条有效样本')\n",
    "    \n",
    "    # 显示数据样例\n",
    "    print('\\n数据样例：')\n",
    "    print(df.head())\n",
    "    \n",
    "    # 显示标签分布\n",
    "    all_labels = [label for labels in df['labels'] for label in labels]\n",
    "    label_counts = pd.Series(all_labels).value_counts()\n",
    "    print('\\n标签分布：')\n",
    "    print(label_counts)\n",
    "    \n",
    "    # 计算类别权重\n",
    "    label_weights = {label: 1.0 / count for label, count in label_counts.items()}\n",
    "    max_weight = max(label_weights.values())\n",
    "    label_weights = {label: weight/max_weight for label, weight in label_weights.items()}\n",
    "    \n",
    "    print('\\n类别权重：')\n",
    "    for label, weight in label_weights.items():\n",
    "        print(f'{label}: {weight:.2f}')\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f'加载数据失败: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 2. 定义标签列表\n",
    "label_list = [\"O\", \"B-MONEY\", \"I-MONEY\", \"B-ACCOUNT\", \"I-ACCOUNT\", \"B-LINK\", \"I-LINK\", \n",
    "             \"B-TIME\", \"I-TIME\", \"B-LOC\", \"I-LOC\", \"B-PHONE\", \"I-PHONE\", \"B-NAME\", \"I-NAME\"]\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "\n",
    "# 3. 标签转为id\n",
    "df['label_ids'] = df['labels'].apply(lambda x: [label2id[l] for l in x])\n",
    "\n",
    "# 4. 划分训练/验证集\n",
    "train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['labels'].apply(lambda x: x[0]))\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "\n",
    "logger.info(f'训练集大小: {len(train_dataset)}, 验证集大小: {len(eval_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 5. 分词器\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['text'], \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        max_length=128,  # 增加最大长度\n",
    "        is_split_into_words=False\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['label_ids']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# 处理数据集\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "logger.info('数据集处理完成')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 6. 定义模型\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    'bert-base-chinese', \n",
    "    num_labels=len(label_list), \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# 7. 训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./bert_ner_antifraud',\n",
    "    num_train_epochs=15,  # 增加训练轮数\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_f1',  # 使用F1作为最佳模型指标\n",
    "    greater_is_better=True,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-5,\n",
    "    # 添加类别权重\n",
    "    label_smoothing_factor=0.1  # 添加标签平滑\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # 只计算非-100的标签\n",
    "    true_labels = []\n",
    "    true_preds = []\n",
    "    for pred, label in zip(predictions, labels):\n",
    "        for p, l in zip(pred, label):\n",
    "            if l != -100:\n",
    "                true_labels.append(l)\n",
    "                true_preds.append(p)\n",
    "    \n",
    "    # 计算多个指标\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(true_labels, true_preds),\n",
    "        'f1': f1_score(true_labels, true_preds, average='macro'),\n",
    "        'precision': precision_score(true_labels, true_preds, average='macro'),\n",
    "        'recall': recall_score(true_labels, true_preds, average='macro')\n",
    "    }\n",
    "    \n",
    "    # 添加每个类别的F1分数\n",
    "    for label in label_list:\n",
    "        label_id = label2id[label]\n",
    "        metrics[f'f1_{label}'] = f1_score(\n",
    "            [1 if l == label_id else 0 for l in true_labels],\n",
    "            [1 if p == label_id else 0 for p in true_preds],\n",
    "            average='binary'\n",
    "        )\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 8. 训练模型\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "logger.info('开始训练...')\n",
    "trainer.train()\n",
    "\n",
    "# 保存模型和分词器\n",
    "output_dir = './bert_ner_antifraud'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "logger.info(f'模型已保存到 {output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 9. 测试模型\n",
    "def predict_entities(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    pred_labels = [id2label[p.item()] for p in predictions[0]]\n",
    "    \n",
    "    # 提取实体\n",
    "    entities = []\n",
    "    current_entity = {\"text\": \"\", \"type\": \"\", \"start\": 0}\n",
    "    \n",
    "    for i, (token, label) in enumerate(zip(tokens, pred_labels)):\n",
    "        if token in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
    "            continue\n",
    "            \n",
    "        if label.startswith(\"B-\"):\n",
    "            if current_entity[\"text\"]:\n",
    "                entities.append(current_entity)\n",
    "            current_entity = {\n",
    "                \"text\": token,\n",
    "                \"type\": label[2:],\n",
    "                \"start\": i\n",
    "            }\n",
    "        elif label.startswith(\"I-\"):\n",
    "            if current_entity[\"text\"]:\n",
    "                current_entity[\"text\"] += token\n",
    "        else:\n",
    "            if current_entity[\"text\"]:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = {\"text\": \"\", \"type\": \"\", \"start\": 0}\n",
    "    \n",
    "    if current_entity[\"text\"]:\n",
    "        entities.append(current_entity)\n",
    "        \n",
    "    return entities\n",
    "\n",
    "# 测试样例\n",
    "test_texts = [\n",
    "    \"恭喜您中奖了50000元，请点击http://prize.com领取奖金\",\n",
    "    \"中奖信息已发放，请联系李经理，电话：13912345678\",\n",
    "    \"您是本月幸运用户，奖金将汇入账号6222000000000000\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    entities = predict_entities(text)\n",
    "    print(f'\\n测试文本: {text}')\n",
    "    print('识别出的实体:')\n",
    "    for entity in entities:\n",
    "        print(f\"类型: {entity['type']}, 文本: {entity['text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}